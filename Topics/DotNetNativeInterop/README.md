# Christian Gunderman's Blog - Thoughts on .NET Native Interop

Ported from a 6 month old LinkedIn post...

## Background

This week marks the close of one of the most difficult and prolonged software investigations that I have ever conducted. A mixed .NET and native application that I contribute to was receiving reports of sporadic, unreproducible crashes in certain scenarios. The application in question is a native application with lots of COM interop, concurrency, COM to .NET, .NET PInvokes, and .NET to COM interop. Eventually, I established the root cause and implemented a surprisingly simple fix, but not before consuming several days in the investigation. In the process, I learned much about debugging large applications, memory corruption, graphs, ref-counting, and especially about how costly it can be to improperly apply defensive programming practices.

## Initial (Misguided) Investigations

Initially, I was unable to reproduce the issue locally. The only thing that I had to go off of were reports of a random crash, and some dump files recording an invalid pointer in native code called from managed code via a PInvoke. The dumps were all in the same DLL, a 3rd party library, but each time, there was a different invalid pointer error or stack overflow error and each time it was in a different place in the code.

My initial gut instinct was that there was an undocumented bug in the 3rd party library leading to memory corruption, and eventually, dereference of an invalid pointer. Eventually, I obtained a local repro, that would non-deterministically fail on a large set of inputs after 45 minutes. Each time, the crash occurred on a different input with no apparent pattern. In order to track down the root cause of the memory corruption, over the course of several days, I attempted to reproduce the crash under App Verifier and PageHeap.

For the uninitiated, PageHeap is a tool for detection of memory corruption in Windows applications via the use of a specialized allocator that adds guard pages before and after each allocation and a distinctive pattern to the unused memory in the page containing the end of the allocated block. If an application attempts to access the area immediately before the allocation, the guard page triggers an access violation exception that causes a debugger break on the offending line. The same is true for any accesses to the guard page following the allocation. However, this leaves ((ceil(alloc_size / page_size) * page_size) - alloc_size) bytes of unprotected memory immediately after each allocation. What this means is that after your allocation of, say, 100 bytes, there is usually around 3996 bytes of memory that is not protected by PageHeap. To ensure that these areas are checked for invalid accesses, PageHeap allocator writes a distinctive pattern to these areas and checks to see if it changes at free. What this means is that PageHeap is only able to detect invalid writes to this area of memory, and only after some delay, so, PageHeap misses any invalid reads to this area, and in a manner reminiscent of the [ABA threading problem](https://en.wikipedia.org/wiki/ABA_problem), if the value is changed, and then changed back before free, it misses those errors as well.

My initial results with PageHeap were promising. After a few minutes of running, I was seeing access violation exceptions with WinDBG in code higher up the stack that called into my area. Initially, I took this as a sign that memory corruption induced higher up the stack was causing a crash in my code. It turns out that I was wrong, and that the CLR actually synthesizes NullPointerExceptions by detecting and handling native access violation exceptions, and that the error I was seeing was an exception in managed code that was not detected by WinDBG because I had not loaded the .NET debugging WinDBG extension.

I tried again, this time, swallowing the misdiagnosed managed exception and then began to hit crashes in mscorlib.dll. I thought once again that I was onto something, and that there was a source of memory corruption leading now to crashes in other parts of the code.
What I eventually came to realize is that PageHeap was leading to the crash in this scenario. Not because of detection of a memory error, but because of exhaustion of all physical memory. To go back to the prior paragraph on PageHeap, PageHeap "adds guard pages before and after each allocation." On the typical x86 Windows system, the page size is 4KB. What this means is that every allocation now takes a minimum of **12KB**, 4KB for the leading page, 4KB for the trailing page, and 4KB for the data page. If the allocated block is more than 4KB in size, this may jump to **16KB or more**! The process wasn't crashing due to detected memory corruption, it was crashing due to memory exhaustion. At this point, I thought that perhaps I could apply the same techniques as PageHeap to just a portion of the process in an attempt to localize the heap corruption detection to just the 3rd party library where the crash occurred. I spent an hour or so and wrote a custom allocator that wrapped VirtualAlloc and VirutalFree and added guard pages before and after each allocation along with tail checking on the data page. Running through the crash scenario again caused a crash, but without tripping my poor-man's PageHeap.

Without a quick repro, I was left with many 45 minute segments of time with which I could perform other investigations, so I took this time to attempt to repro the same crash out of process. Doing so, I found something curious: the crash only occurred in the big application process, and not in a standalone console app. Even in massively concurrent scenarios, no crash occurred, despite only occurring in concurrent scenarios in the actual application.

## Manual Inspection

At this point, I decided to manually inspect both the managed calling code and the native callee code for hazardous memory usage and race conditions. I inspected hundreds of lines of PInvokes (C# invocation of dynamically loaded native DLL's), unsafe classes (pointers, structs, mallocs, and frees in .NET code), and reviewed the third party open source library's usages of malloc, free, alloca (terrifying by-the-way, potentially undefined behavior on stack exhaustion), and hundreds of lines of concurrent code, synchronized entirely by [atomic](https://msdn.microsoft.com/en-us/library/system.threading.volatile.read(v=vs.110).aspx) and [interlocked](https://msdn.microsoft.com/en-us/library/system.threading.interlocked(v=vs.110).aspx) operations. Though all of this made me nervous, I failed to find "the smoking gun." What I did realize, however, is that our code was reusing natively allocated structs in cases in which the 3rd party library returned an error and I hypothesized that perhaps there were error conditions in which the structs could be corrupted or invalidated and I devised a change that I thought might correct the issue, however, with such an inconsistent repro, I was unable to confidently and fully justify the change.

## Ahah!

Finally, someone reached out to me and shared the details of a consistent repro for the crash that only took 35 seconds. With my newfound ability to test my hypotheses, I implemented error code checking to find that it did in fact prevent the crash, though it wasn't the correct fix. As it turns out, the pointer fed into the native library from the managed code is invalid due to a use-after-free and the error code is due to the library attempting to read the memory pointed to by the pointer as bytecode. Since this is still memory within our process's address space, we can read it just fine. Some of the time, the library returns invalid bytecode errors, but occasionally, the memory pointed to by the pointers were just such that the library recursed repeatedly, causing a stack overflow.

## Error Scenario: Graphs, Ref-Counting, and Cycles

At the end of the day, the crash was due to a use-after-free of a native struct that was marshalled from managed code to native code, resulting from invalid ref-counting in the resource graph in the application.
The application makes use of a series of resources, that form nodes in a graph and are ref-counted to ensure deletion of unmanaged memory. Each root resource is a resource that is currently being held directly by an external consumer. Within the graph, are other nodes that are children of the roots. One at first envisions a tree-like structure, with some roots also acting as children of other roots, however, it is possible for there to be cycles in the resource graph, so, to ensure an accurate ref-count, and to avoid leaks, the roots own the references to all of the children.
In the crash scenario, some resource A, takes a dependency on B, which depends on C. At first usage, explicit references to B and C are lazily added to A. A, B, and C now have ref-counts of 1 each. There exists a caching mechanism to reduce the overhead of synchronizing concurrent accesses to child nodes, so, the contents of C are cached inside of B during the first walk. Then, another job comes along and initializes D which depends on B and C. The ref-counts are now 1, 2, 1, 1, for A, B, C, and D, respectively, because the caching of C in B prevented D from ever walking into C, such that D does not own an explicit reference to C. When A is freed, C is as well, and the native resources associated with C are freed and the pointers are nulled out, causing a null-pointer crash at the first usage of the freed memory. The bug was easy to solve. The end.

What actually happens is that the pointers are encapsulated within structs, which in C# code are memory that is passed by value. In an unfortunate oversight, these pointers within structs are nulled in a method, meaning that the original value stored in the node itself is not modified and the dangling pointers live on after the memory has met its end.

These pointers are then fed into the native library. Most of the time, the freed memory has not yet been changed and the process spins on, but eventually, these pointers point to memory that has been modified since, and the application crashes, hence the wide-variety of stack traces associated with this crash, and the difficulty tracking down a root cause.

## Takeaways

Save developers that come after you the headache and always null out pointers to freed memory to ensure that your application fails quickly and close to the root cause. Invalid pointers only consistently cause detectable failures near the point of origin on a write operation, so, in scenarios where the invalid pointer is only read, it is often impossible to find use-after-frees with PageHeap or Application Verifier. A null pointer, however, would crash immediately at first usage, making the root cause of a use-after-free much more apparent.
In complex allocation scenarios for trees and graphs, always have tests or debug asserts in place that can catalog all allocs, frees, and cause a failure on use after free, duplicate free, or memory leak.

Finally, be very mindful of code that is pass by value instead of pass by reference. In particular, .NET code that performs native interop usually contains structs and is a prime candidate for introducing such errors.

